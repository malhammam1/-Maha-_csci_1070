{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMnJ5IcbAJl4R7gn9Ei4HY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malhammam1/Maha_csci_1070/blob/master/Assignment_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYJZS-U6GBk4",
        "outputId": "459a4f71-7596-47bf-b534-ee7167bb41da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Maha_csci_1070'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 53 (delta 18), reused 31 (delta 6), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (53/53), 153.40 KiB | 5.48 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/malhammam1/Maha_csci_1070.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RICgGSvGDNm",
        "outputId": "8cebb479-a4a4-4a3b-a4e8-16bab7a3b904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Maha_csci_1070/csci_1070/Maha_csci_1070\n"
          ]
        }
      ],
      "source": [
        "%cd Maha_csci_1070"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lexmckenz/csci_1070.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evn70TikgXJp",
        "outputId": "305f1e56-97ee-41e0-a387-3a3092169b48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'csci_1070'...\n",
            "remote: Enumerating objects: 206, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 206 (delta 16), reused 29 (delta 6), pack-reused 165\u001b[K\n",
            "Receiving objects: 100% (206/206), 14.54 MiB | 18.75 MiB/s, done.\n",
            "Resolving deltas: 100% (78/78), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd csci_1070"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHDDJ4EGgcPW",
        "outputId": "84d288d7-ef31-42c3-ded7-79b683c2c40c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Maha_csci_1070/csci_1070/Maha_csci_1070/csci_1070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# If there's a space in the file name, it needs to be handled properly\n",
        "zip_path = '/content/Maha_csci_1070/archive (3).zip'\n",
        "\n",
        "# Unzipping the file\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/Maha_csci_1070/')\n",
        "    print(\"File unzipped successfully\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {zip_path}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"File is not a zip file or is corrupted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "868cR4z9ghjb",
        "outputId": "774a3484-0b09-4632-8e1b-26c138f3aba2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File unzipped successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is a Neural Network?\n",
        "A Neural Network is a series of algorithms that attempts to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates. Neural Networks can adapt to changing input; so the network generates the best possible result without needing to redesign the output criteria.\n",
        "\n",
        "## General Steps to Build a Neural Network\n",
        "1. **Data Preprocessing:** Load and preprocess data to a suitable format.\n",
        "2. **Define Model:** Choose the type of model and number of layers.\n",
        "3. **Compile Model:** Select the optimizer, loss function, and metrics.\n",
        "4. **Train Model:** Fit the model on the training data.\n",
        "5. **Evaluate Model:** Assess the model using a test set.\n",
        "6. **Parameter Tuning:** Adjust hyperparameters as needed.\n",
        "7. **Prediction:** Use the model to make predictions.\n"
      ],
      "metadata": {
        "id": "f_WDkAzRjSp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning Improvements\n",
        "\n",
        "For this dataset, the following data cleaning steps were performed to ensure the quality and readiness of the data for modeling:\n",
        "1. **Handling Missing Values:** Used imputation to handle missing values in both categorical and numerical data. This ensures that the model has a complete dataset to learn from.\n",
        "2. **Feature Encoding:** Applied one-hot encoding to categorical variables to convert them into a form that could be provided to the ML models to do a better job in prediction.\n",
        "3. **Scaling:** Standardized the range of the numerical data fields to ensure that no variable dominates another due to its scale.\n",
        "\n",
        "These steps are critical to making the predictive model reliable and robust.\n"
      ],
      "metadata": {
        "id": "6EF07qAKBfCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/Maha_csci_1070/Credit_card.csv')\n",
        "\n",
        "\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "\n",
        "X = df.drop('Car_Owner', axis=1)\n",
        "y = df['Car_Owner'].apply(lambda x: 1 if x == 'Y' else 0)\n",
        "\n",
        "\n",
        "numerical_cols = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)])\n",
        "\n",
        "\n",
        "X = preprocessor.fit_transform(X)\n",
        "X = np.array(X, dtype=np.float32)\n",
        "y = np.array(y, dtype=np.float32)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=[X.shape[1]]),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
        "\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Model accuracy on test set:\", accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChMNKks0JxHX",
        "outputId": "a30b0385-ace1-4ab3-bb51-1f4885695764"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "31/31 [==============================] - 2s 14ms/step - loss: 0.6878 - accuracy: 0.5444 - val_loss: 0.6247 - val_accuracy: 0.6653\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6141 - accuracy: 0.6616 - val_loss: 0.6079 - val_accuracy: 0.6774\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.5767 - accuracy: 0.7071 - val_loss: 0.6067 - val_accuracy: 0.6653\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5574 - accuracy: 0.7232 - val_loss: 0.6052 - val_accuracy: 0.6774\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7364 - val_loss: 0.6166 - val_accuracy: 0.6815\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5402 - accuracy: 0.7333 - val_loss: 0.6098 - val_accuracy: 0.6774\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5268 - accuracy: 0.7434 - val_loss: 0.6087 - val_accuracy: 0.6734\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5177 - accuracy: 0.7455 - val_loss: 0.6142 - val_accuracy: 0.6734\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5091 - accuracy: 0.7525 - val_loss: 0.6119 - val_accuracy: 0.6734\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7556 - val_loss: 0.6143 - val_accuracy: 0.6855\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6871\n",
            "Model accuracy on test set: 0.6870967745780945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the Performance of Neural Networks\n",
        "\n",
        "To check the performance of a neural network, we typically use metrics such as accuracy, loss, precision, recall, and F1-score, depending on the specific requirements of the task. For classification tasks, accuracy is a common metric, representing the proportion of correctly predicted observations to the total observations.\n",
        "\n",
        "- **Why:** These metrics help in understanding how well the model is performing on unseen data, ensuring that it generalizes well rather than just memorizing the training data. This is crucial for determining the effectiveness of the model in real-world scenarios.\n"
      ],
      "metadata": {
        "id": "Bd8mTLOHAcLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "log_reg_model = LogisticRegression()\n",
        "\n",
        "\n",
        "log_reg_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "log_reg_predictions = log_reg_model.predict(X_test)\n",
        "\n",
        "log_reg_accuracy = accuracy_score(y_test, log_reg_predictions)\n",
        "print(\"Logistic Regression Model accuracy on test set:\", log_reg_accuracy)\n",
        "\n",
        "print(\"Neural Network accuracy on test set:\", accuracy)\n",
        "print(\"Logistic Regression accuracy on test set:\", log_reg_accuracy)\n",
        "\n",
        "print(\"\\nComparison Discussion:\")\n",
        "if log_reg_accuracy > accuracy:\n",
        "    print(\"The Logistic Regression model performed better. This might be due to its simplicity and the linear nature of the data.\")\n",
        "else:\n",
        "    print(\"The Neural Network performed better. This might be due to its ability to capture nonlinear patterns in the data, which Logistic Regression cannot.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7PrarjIgsNi",
        "outputId": "11e61372-f372-419a-ecd0-57c741edab57"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model accuracy on test set: 0.6741935483870968\n",
            "Neural Network accuracy on test set: 0.6870967745780945\n",
            "Logistic Regression accuracy on test set: 0.6741935483870968\n",
            "\n",
            "Comparison Discussion:\n",
            "The Neural Network performed better. This might be due to its ability to capture nonlinear patterns in the data, which Logistic Regression cannot.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison with Logistic Regression Model\n",
        "\n",
        "The neural network model achieved a higher accuracy on the test set compared to the logistic regression model. The neural network's accuracy was 0.6870 while the logistic regression's was 0.6741. The superior performance of the neural network can likely be attributed to its ability to model complex non-linear relationships between features, which is not possible with logistic regression. Logistic regression assumes linearity between the dependent variable and the independent variables, which might not be the case in our dataset.\n"
      ],
      "metadata": {
        "id": "njLwq7CjCsLb"
      }
    }
  ]
}